# About MachineLearning
## 선형 회귀(Linear Regression)
특정 음식을 처음 요리하는 사람은 요리를 반복하여 연습하면 할 수록 더 완성도가 높은 음식이 나온다. 어느 정도의 연습이 끝나면,
완성된 음식은 대중적으로 대부분 만족하는 음식에 가까워져 있을 것이다.
이는 수학적으로 생각해보면, 어떤 요인의 수치에 따라 특정 요인의 수치가 영향을 받고있다고 할 수 있다.

선형 회귀 모델은 지도학습 알고리즘으로 주로 수치예측 문제에 사용한다. 독립변수를 이용하여 종속변수를 예측하는 모델이다.
이러한 모델에서는, 오차들의 합이 가장 작은경우가 좋은 모델이라고 한다.<br>

## K-NN Algorithm
분류와 군집화 - 지도학습 And 비지도 학습
* 분류 - 소속집단의 정보를 이미 알고 있는 상태에서 비슷한 집단으로 묶는 방법
* 군집화 - 소속집단의 정보가 없는 상태에서 비슷한 집단으로 묶는 방법

K-NN알고리즘은 특징 공간에 분포하는 데이터에 대하여 k개의 가장 가까운 이웃을 살펴보고 다수결 방식으로 데이터의 레이블을 할당하는 분류방식이다.<br>
이는 단순하고 직관적이며 사전학습이나 특별한 준비 시간이 필요없다는 점이 장점이다.<br>
K평균 알고리즘은 군집의 개수에 따라 데이터를 군집으로 분류하는 알고리즘으로 원리가 단순하고 직관적이며, 성능이 좋은군집화 알고리즘으로 사전에 군집의 개수 k 값을 지정해야 한다.

## 다항회귀/결정트리/SVM
* 다항회귀 - 3차 다항식과 같은 (x+1)^3의 계수를 조정하는 문제로 함수를 찾아 내는 것이다. <br>
-다항회귀는 훈련용 데이터에만 지나치게 맞춰진 과적합으로 훈련때에는 좋은 성능을 보이지만 실제 응용시 오차율이 매우 높아져 잘못 예측되는 경우가 많다.
* 결정트리 - 귀납 추론을 위해 자주 사용되는 실용적인 방법으로 트리구조에서 ROOT > Internal Node > Leaf Node 로 거쳐 배정하는 기능을 수행한다.<br>
-결정트리의 가장 큰 장점은 시각화하고 편하고, 직관적으로 이해가 가능하다는 것이다. 또, 데이터의 스케일에 구애받지 않는다. 각 피처가 개별적으로 처리되어 데이터를 분할하는데 데이터 스케일의 영향을 받지 않으므로, 결정트리에서는 피처 정규화나 표준화 같은 전처리 과정이 필요없다.
주요 단점은 pruning(가지치기)를 사용해도 과대적합되는 경향이 있어 일반화 성능이 좋지 않다는 것이다. 이를 대신해 앙상블 기법을 단일 결정트리의 대안으로 흔히 사용한다.
* SVM - 서포트 벡터 머신을 줄여서 말한다. 딥러닝을 통해 인공지능 분야의 중심으로 떠오르기 전에 각광받헌 학습중의 하나이며, 머신러닝 알고리즘중에서 가장 많이 사용되는 알고리즘중 하나. <br>
-이는 오류 데이터 영향이 적으며, 과적합이 되는 경우가 적다. 신경망보다 사용하기 쉽다. 그러나 학습속도가 느리며, 여러개의 조합테스트가 필요하다.
